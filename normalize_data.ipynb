{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate movement 1-down\n",
      "Min rows after 1-down equals 4155\n",
      "Calculate movement 2-up\n",
      "Min rows after 2-up equals 4155\n",
      "Calculate movement 0-static\n",
      "Min rows after 0-static equals 4155\n",
      "==========================================\n",
      "Minimum of rows in files equal 4155\n"
     ]
    }
   ],
   "source": [
    "movements_folder_path = \"movements\"\n",
    "movements = os.listdir(movements_folder_path)\n",
    "movements.remove(\".DS_Store\")\n",
    "\n",
    "min_rows_number = float(\"inf\")\n",
    "\n",
    "for movement in movements:\n",
    "    file_list = os.listdir(os.path.join(movements_folder_path, movement))\n",
    "    print(f\"Calculate movement {movement}\")\n",
    "\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(movements_folder_path, movement, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        min_rows_number = min(df.shape[0], min_rows_number)\n",
    "\n",
    "    print(f\"Min rows after {movement} equals {min_rows_number}\")\n",
    "\n",
    "print(f\"==========================================\\nMinimum of rows in files equal {min_rows_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resize movement 1-down\n",
      "Resize movement 2-up\n",
      "Resize movement 0-static\n"
     ]
    }
   ],
   "source": [
    "for movement in movements:\n",
    "    file_list = os.listdir(os.path.join(movements_folder_path, movement))\n",
    "    print(f\"Resize movement {movement}\")\n",
    "\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(movements_folder_path, movement, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        state = 0\n",
    "        while df.shape[0] != min_rows_number:\n",
    "            if state == 0:\n",
    "                df = df.drop(df.index[0])\n",
    "                state = 1\n",
    "            else:\n",
    "                df = df.drop(df.index[-1])\n",
    "                state = 0\n",
    "\n",
    "        df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length = 303\n",
      "same size\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "\n",
    "for movement in movements:\n",
    "    file_list = os.listdir(os.path.join(movements_folder_path, movement))\n",
    "\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(movements_folder_path, movement, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        features.append(df)\n",
    "\n",
    "print(f\"length = {len(features)}\")\n",
    "\n",
    "for feature in features:\n",
    "    if feature.shape[0] != min_rows_number:\n",
    "        print(\"not same size\")\n",
    "        break\n",
    "\n",
    "print(\"same size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем обучить модель для классификации 3-х движений:\n",
    "* **0** (статика)\n",
    "* **1** (движение кисти вниз)\n",
    "* **2** (движение кисти вверх)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = pd.DataFrame(columns=[\"data\", \"target\"])\n",
    "cols = [\n",
    "    \"Time (sec)\",\n",
    "    \"Pitch (deg)\",\n",
    "    \"Roll (deg)\",\n",
    "    \"Yaw(deg)\",\n",
    "    \"X-Acceleration (g)\",\n",
    "    \"Y-Acceleration (g)\",\n",
    "    \"Z-Acceleration (g)\",\n",
    "    \"Pitch Rate (deg/sec)\",\n",
    "    \"Roll Rate (deg/sec)\",\n",
    "    \"Yaw Rate (deg/sec)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_vector(matrix):\n",
    "    res = []\n",
    "\n",
    "    for row in matrix:\n",
    "        for element in row:\n",
    "            res.append(element)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 3, 1, 2, 3, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix = [\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [6, 1, 2, 3, 4],\n",
    "    [1, 3, 1, 2, 3],\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 2, 2, 2, 2]\n",
    "]\n",
    "\n",
    "matrix_to_vector(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for movement in movements:\n",
    "    file_list = os.listdir(os.path.join(movements_folder_path, movement))\n",
    "\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(movements_folder_path, movement, file)\n",
    "\n",
    "        temp = pd.read_csv(file_path)\n",
    "        temp = temp[cols]\n",
    "        matrix = temp.to_numpy()\n",
    "        vector = matrix_to_vector(matrix)\n",
    "\n",
    "        if movement == \"0-static\":\n",
    "            my_dataset.loc[len(my_dataset.index)] = [vector, 0]\n",
    "        elif movement == \"1-down\":\n",
    "            my_dataset.loc[len(my_dataset.index)] = [vector, 1]\n",
    "        elif movement == \"2-up\":\n",
    "            my_dataset.loc[len(my_dataset.index)] = [vector, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [729705840.312976, -1.531345, 3.288962, 73.756...\n",
       "1      [729717183.336099, -0.793636, 3.283734, 143.26...\n",
       "2      [729707040.25009, -18.376733, 2.053893, 115.15...\n",
       "3      [729705462.529353, -0.223319, 0.623548, 72.340...\n",
       "4      [729706791.925182, -0.227171, 1.687749, -22.98...\n",
       "                             ...                        \n",
       "904    [729606399.147986, 0.700881, 0.952782, 50.2873...\n",
       "905    [729600931.425837, 0.988402, 0.870238, -3.8260...\n",
       "906    [729608352.74702, 1.217515, -0.662269, 55.3426...\n",
       "907    [729601272.717378, 0.654508, -1.17449, -20.611...\n",
       "908    [729608486.813546, 1.70852, -4.029911, 55.9137...\n",
       "Name: data, Length: 909, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_dataset['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41550"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_dataset['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Точность модели: 0.26373626373626374\n"
     ]
    }
   ],
   "source": [
    "data = np.array(my_dataset['data'].to_list())\n",
    "target = np.array(my_dataset['target'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data,\n",
    "    target,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(50, 50), (100, 100), (100, 50, 25)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'max_iter': [1000, 1500, 2000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=MLPClassifier(), param_grid=parameters, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "model = MLPClassifier(**best_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание целевых значений на тестовом наборе\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"===============================\")\n",
    "print(y_pred)\n",
    "\n",
    "# Оценка модели\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Точность модели: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    my_dataset[\"data\"],\n",
    "    my_dataset[\"target\"],\n",
    "    shuffle=True,\n",
    "    test_size=0.2,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m log_reg \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m log_reg\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1207\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1205\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1207\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1208\u001b[0m     X,\n\u001b[1;32m   1209\u001b[0m     y,\n\u001b[1;32m   1210\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n\u001b[1;32m   1212\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1213\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1214\u001b[0m )\n\u001b[1;32m   1215\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/sklearn/base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m     )\n\u001b[0;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1148\u001b[0m     X,\n\u001b[1;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[1;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[1;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[1;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    921\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m/usr/local/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:917\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    872\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    916\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m--> 917\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    919\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
